for(i in 1:length(all_links)){
if(i%%100){
cat("on article ",i," of ",length(all_links),"\n",sep="")
}
current_article <- paste0(baseurl,all_links[i])
dates <- current_article %>%
read_html() %>%
html_nodes(".c-bibliographic-information__value") %>%
html_text()
all_dates[((i-1)*4+1):(i*4)] <- dates
}
head(all_links)
table(all_links=="")
all_links <- all_links[!(all_links=="")]
for(i in 1:length(all_links)){
if(i%%100){
cat("on article ",i," of ",length(all_links),"\n",sep="")
}
current_article <- paste0(baseurl,all_links[i])
dates <- current_article %>%
read_html() %>%
html_nodes(".c-bibliographic-information__value") %>%
html_text()
all_dates[((i-1)*4+1):(i*4)] <- dates
}
all_dates <- rep("A",4*length(all_links)) #pre-allocate to save a little time
for(i in 1:length(all_links)){
if((i%%100)==0){
cat("on article ",i," of ",length(all_links),"\n",sep="")
}
current_article <- paste0(baseurl,all_links[i])
dates <- current_article %>%
read_html() %>%
html_nodes(".c-bibliographic-information__value") %>%
html_text()
all_dates[((i-1)*4+1):(i*4)] <- dates
}
for(i in 4700:length(all_links)){
if((i%%100)==0){
cat("on article ",i," of ",length(all_links),"\n",sep="")
}
current_article <- paste0(baseurl,all_links[i])
dates <- current_article %>%
read_html() %>%
html_nodes(".c-bibliographic-information__value") %>%
html_text()
cat(dates,"\n",sep="")
all_dates[((i-1)*4+1):(i*4)] <- dates
}
for(i in 4700:length(all_links)){
if((i%%100)==0){
cat("on article ",i," of ",length(all_links),"\n",sep="")
}
current_article <- paste0(baseurl,all_links[i])
dates <- current_article %>%
read_html() %>%
html_nodes(".c-bibliographic-information__value") %>%
html_text()
cat(dates,"\n",sep=" ")
all_dates[((i-1)*4+1):(i*4)] <- dates
}
unique(dates)
length(dates)
install.packages("doParallel")
library(doParallel)
cl <- makeCluster(10)
registerDoParallel(cl,cores = 10)
baseurl <- "https://bmcgenomics.biomedcentral.com"
all_dates_list <- foreach(i in 4700:length(all_links)) %dopar% {
all_dates_list <- foreach(i=1:length(all_links)) %dopar% {
current_article <- paste0(baseurl,all_links[i])
dates <- current_article %>%
read_html() %>%
html_nodes(".c-bibliographic-information__value") %>%
html_text()
#if(length(dates)==4){ # a few articles seem to be missing the process dates
#    all_dates[((i-1)*4+1):(i*4)] <- dates
#}
return(dates)
}
stopCluster(cl)
stopCluster(cl)
?foreach
cl <- makeCluster(10)
cl <- makeCluster(10)
registerDoParallel(cl,cores = 10)
stopCluster(cl)
knitr::opts_chunk$set(echo = TRUE)
library(rvest)
library(stringr); library(tidyr)
url <- 'https://bmcgenomics.biomedcentral.com/articles?searchType=journalSearch&sort=PubDate&page='
all_links <- ""
for(i in 1:248){
current_url <- paste0(url,i)
links <- current_url %>%
read_html() %>%
html_nodes("a") %>%
html_attr(name = "href")
current_links <- links[str_detect(links, "^/articles/")]
all_links <- c(all_links,current_links[-c(1:3)])
}
all_links <- all_links[!(all_links=="")]
library(doParallel)
cl <- makeCluster(10)
registerDoParallel(cl,cores = 10)
baseurl <- "https://bmcgenomics.biomedcentral.com"
all_dates_list <- foreach(i=1:length(all_links), .packages = c(rvest,stringr,tidyr)) %dopar% {
current_article <- paste0(baseurl,all_links[i])
dates <- current_article %>%
read_html() %>%
html_nodes(".c-bibliographic-information__value") %>%
html_text()
#if(length(dates)==4){ # a few articles seem to be missing the process dates
#    all_dates[((i-1)*4+1):(i*4)] <- dates
#}
return(dates)
}
all_dates_list <- foreach(i=1:length(all_links), .packages = c("rvest","stringr","tidyr")) %dopar% {
current_article <- paste0(baseurl,all_links[i])
dates <- current_article %>%
read_html() %>%
html_nodes(".c-bibliographic-information__value") %>%
html_text()
#if(length(dates)==4){ # a few articles seem to be missing the process dates
#    all_dates[((i-1)*4+1):(i*4)] <- dates
#}
return(dates)
}
dim(all_dates_list)
all_dates_list <- foreach(i=1:l20, .packages = c("rvest","stringr","tidyr")) %dopar% {
current_article <- paste0(baseurl,all_links[i])
dates <- current_article %>%
read_html() %>%
html_nodes(".c-bibliographic-information__value") %>%
html_text()
#if(length(dates)==4){ # a few articles seem to be missing the process dates
#    all_dates[((i-1)*4+1):(i*4)] <- dates
#}
return(dates)
}
all_dates_list <- foreach(i=1:20, .packages = c("rvest","stringr","tidyr")) %dopar% {
current_article <- paste0(baseurl,all_links[i])
dates <- current_article %>%
read_html() %>%
html_nodes(".c-bibliographic-information__value") %>%
html_text()
#if(length(dates)==4){ # a few articles seem to be missing the process dates
#    all_dates[((i-1)*4+1):(i*4)] <- dates
#}
return(dates)
}
all_dates_list <- foreach(i=1:20, .packages = c("rvest","stringr","tidyr")) %dopar% {
current_article <- paste0(baseurl,all_links[i])
dates <- current_article %>%
read_html() %>%
html_nodes(".c-bibliographic-information__value") %>%
html_text()
#if(length(dates)==4){ # a few articles seem to be missing the process dates
#    all_dates[((i-1)*4+1):(i*4)] <- dates
#}
return(dates)
}
stopCluster(cl)
cl <- makeCluster(10)
registerDoParallel(cl,cores = 10)
baseurl <- "https://bmcgenomics.biomedcentral.com"
all_dates_list <- foreach(i=1:20, .packages = c("rvest","stringr","tidyr")) %dopar% {
current_article <- paste0(baseurl,all_links[i])
dates <- current_article %>%
read_html() %>%
html_nodes(".c-bibliographic-information__value") %>%
html_text()
#if(length(dates)==4){ # a few articles seem to be missing the process dates
#    all_dates[((i-1)*4+1):(i*4)] <- dates
#}
return(dates)
}
all_dates_list <- foreach(i=1:20, .packages = c("rvest","stringr","tidyr")) %dopar% {
current_article <- paste0(baseurl,all_links[i])
dates <- current_article %>%
read_html() %>%
html_nodes(".c-bibliographic-information__value") %>%
html_text()
#if(length(dates)==4){ # a few articles seem to be missing the process dates
#    all_dates[((i-1)*4+1):(i*4)] <- dates
#}
return(dates)
}
dim(all_dates_list)
all_dates_list
length(all_links)
all_dates_list <- foreach(i=1:20, .packages = c("rvest","stringr","tidyr")) %dopar% {
if((i%%100)==0){
cat("on article ",i," of ",length(all_links),"\n",sep="")
}
current_article <- paste0(baseurl,all_links[i])
dates <- current_article %>%
read_html() %>%
html_nodes(".c-bibliographic-information__value") %>%
html_text()
#if(length(dates)==4){ # a few articles seem to be missing the process dates
#    all_dates[((i-1)*4+1):(i*4)] <- dates
#}
return(dates)
}
all_dates_list <- foreach(i=1:200, .packages = c("rvest","stringr","tidyr")) %dopar% {
if((i%%10)==0){
cat("on article ",i," of ",length(all_links),"\n",sep="")
}
current_article <- paste0(baseurl,all_links[i])
dates <- current_article %>%
read_html() %>%
html_nodes(".c-bibliographic-information__value") %>%
html_text()
#if(length(dates)==4){ # a few articles seem to be missing the process dates
#    all_dates[((i-1)*4+1):(i*4)] <- dates
#}
return(dates)
}
2500/60
2500/60*1.5
getwd()
install.packages("keras")
keras::install_keras()
library(keras)
library(keras)
mnist <- dataset_mnist()
x_train <- mnist$train$x
y_train <- mnist$train$y
x_test <- mnist$test$x
y_test <- mnist$test$y
dim(mnist)
length(mnnist)
length(mnist)
str(mnist)
x_train <- array_reshape(x_train, c(nrow(x_train), 784))
x_test <- array_reshape(x_test, c(nrow(x_test), 784))
# rescale
x_train <- x_train / 255
x_test <- x_test / 255
y_train <- to_categorical(y_train, 10)
y_test <- to_categorical(y_test, 10)
head(y_train)
model <- keras_model_sequential()
model %>%
layer_dense(units = 256, activation = 'relu', input_shape = c(784)) %>%
layer_dropout(rate = 0.4) %>%
layer_dense(units = 128, activation = 'relu') %>%
layer_dropout(rate = 0.3) %>%
layer_dense(units = 10, activation = 'softmax')
summary(model)
model %>% compile(
loss = 'categorical_crossentropy',
optimizer = optimizer_rmsprop(),
metrics = c('accuracy')
)
fit()
history <- model %>% fit(
x_train, y_train,
epochs = 30, batch_size = 128,
validation_split = 0.2
)
library(ggplot2)
head(cars)
plot(x=cars$dist,y=cars$speed)
ggplot(data=cars,aes(x=dist,y=speed))
ggplot(data=cars,aes(x=dist,y=speed)) + geom_point()
p<-ggplot(data=cars,aes(x=dist,y=speed)) + geom_point()
p<-ggplot(data=cars,aes(x=dist,y=speed)) + geom_point()
p
?plot
plot(x=cars$dist,y=cars$speed,pch=20)
ggplot(data=cars,aes(x=dist,y=speed)) + geom_point()
ggplot(data=cars,aes(x=dist,y=speed)) + geom_point() + theme_dark()
ggplot(data=cars,aes(x=dist,y=speed)) + geom_point() + theme_bw()
ggplot(data=cars,aes(x=dist,y=speed)) + geom_point(shape=18) + theme_bw()
ggplot(data=cars,aes(x=dist,y=speed)) + geom_point(shape=18,colour="red") + theme_bw()
192/32
256/24
128/32
24*16
24*32
temp <- read.delim("~/Desktop/tr_99ED04292E5A1572086515576.txt")
head(temp)
300*75*3
300*75*5
516/56
250/56
200/56
3000/332
332-24
y<- exp(1:100)
y
plot(x,y)
plot(1:100,y)
plot(1:100,log(y,10))
plot(1:100,log(y,2))
plot(1:100,sqrt(y))
plot(1:100,log(y,2))
?plot
x<-seq(1:100,by=0.1)
x<-seq(from=1,to=100,by=0.1)
plot(x,2^y)
plot(x,2^x)
plot(x,log(2^x))
plot(x,log(2^x,10))
y<-x^2
plot(x,y)
plot(x,log(y))
plot(x,log(y,10))
y<-x^3
plot(x,log(y,10))
ggplot(aes(x,y))
library(ggplot2)
ggplot(aes(x,y))
ggplot(data.frame(cbind(x,y),aes(x,y))
)
df <- cbind(x,y)
ggplot(df,aes(x,y)) + geom_point()
df <- data.frame(cbind(x,y))
df
head(df)
ggplot(df,aes(x,y)) + geom_point()
ggplot(df,aes(x,y)) + geom_point() + scale_y_log10()
y<-x^2
df <- cbind(x,y)
df <- data.frame(cbind(x,y))
ggplot(df,aes(x,y)) + geom_point() + scale_y_log10()
df <- data.frame(cbind(x,y<-x^1.5))
ggplot(df,aes(x,y)) + geom_point() + scale_y_log10()
df <- data.frame(cbind(x,y<-x^1.1))
ggplot(df,aes(x,y)) + geom_point() + scale_y_log10()
ggplot(df,aes(x,y)) + geom_point()
shiny::runApp('corona/virus-growth')
runApp('corona/virus-growth')
runApp('corona/virus-growth')
runApp('corona/virus-growth')
runApp('corona/virus-growth')
library(flexdashboard)
library(tidyverse)
library(knitr)
library(data.table)
library(kableExtra)
### get list of available EB modules
# get rid of system stuff and template
available_modules <- fread("./easybuild-easyconfigs/easyconfig_list.txt",header=FALSE,data.table=FALSE)
available_module_list <- strsplit(available_modules$V1,"/",fixed=TRUE)
get_last <- function(x_list){
list_len <- length(x_list)
name_file <- c(x_list[list_len-1],x_list[list_len])
return(name_file)
}
available_mod_names <- data.frame(t(sapply(available_module_list,get_last)))
colnames(available_mod_names) <- c("package","bundle version")
head(available_mod_names)
colnames(available_mod_names) <- c("package","bundle.version")
spread(available_mod_names,package,bundle.version)
spread(available_mod_names,bundle.version,package)
?gather
?spread
available_mod_names % pivot_wider(package,bundle.version) %>% head()
available_mod_names %>% pivot_wider(package,bundle.version) %>% head()
available_mod_names %>% pivot_wider(names_from = package,values_from = bundle.version) %>% head()
head(available_mod_names)
temp<-head(available_mod_names)
temp %>% spread(package,bundle.version)
temp %>% pivot_wider(values_from=bundle.version)
temp %>% pivot_wider(values_from=bundle.version,names_from=package)
temp %>% pivot_wider(values_from=bundle.version,names_from=package)
available_mod_names$combined.packages <- NA
for(i in 2:nrow(available_mod_names)){
if(available_mod_names$package[i]==available_mod_names$package[i-1]){
available_mod_names$bundle.version[i]=paste0(available_mod_names$bundle.version[i-1],",",available_mod_names$bundle.version[i])
}
}
available_module_list <- strsplit(available_modules$V1,"/",fixed=TRUE)
get_last <- function(x_list){
list_len <- length(x_list)
name_file <- c(x_list[list_len-1],x_list[list_len])
return(name_file)
}
available_mod_names <- data.frame(t(sapply(available_module_list,get_last)))
colnames(available_mod_names) <- c("package","bundle.version")
head(available_mod_names)
for(i in 2:6){ ##2:nrow(available_mod_names)){
if(available_mod_names$package[i]==available_mod_names$package[i-1]){
available_mod_names$bundle.version[i]=paste0(available_mod_names$bundle.version[i-1],",",available_mod_names$bundle.version[i])
}
}
head(available_mod_names)
available_mod_names <- data.frame(t(sapply(available_module_list,get_last)))
head(available_mod_names)
paste0(available_mod_names$bundle.version[i-1],",",available_mod_names$bundle.version[i])
i
available_mod_names$bundle.version[i-1]
available_mod_names
head(available_mod_names)
available_mod_names <- data.frame(t(sapply(available_module_list,get_last)))
colnames(available_mod_names) <- c("package","bundle.version")
head(available_mod_names)
paste0(available_mod_names$bundle.version[i-1],",",available_mod_names$bundle.version[i])
available_mod_names$bundle.version[i] <- paste0(available_mod_names$bundle.version[i-1],", ",available_mod_names$bundle.version[i])
### get list of available EB modules
# get rid of system stuff and template
available_modules <- fread("./easybuild-easyconfigs/easyconfig_list.txt",header=FALSE,data.table=FALSE,stringsAsFactors=FALSE)
available_module_list <- strsplit(available_modules$V1,"/",fixed=TRUE)
get_last <- function(x_list){
list_len <- length(x_list)
name_file <- c(x_list[list_len-1],x_list[list_len])
return(name_file)
}
available_mod_names <- data.frame(t(sapply(available_module_list,get_last)),stringsAsFactors=FALSE)
colnames(available_mod_names) <- c("package","bundle.version")
for(i in 2:6){ ##2:nrow(available_mod_names)){
if(available_mod_names$package[i]==available_mod_names$package[i-1]){
available_mod_names$bundle.version[i] <- paste0(available_mod_names$bundle.version[i-1],", ",available_mod_names$bundle.version[i])
}
}
head(available_mod_names)
available_mod_names <- data.frame(t(sapply(available_module_list,get_last)),stringsAsFactors=FALSE)
colnames(available_mod_names) <- c("package","bundle.version")
for(i in 2:nrow(available_mod_names)){
if(available_mod_names$package[i]==available_mod_names$package[i-1]){
available_mod_names$bundle.version[i] <- paste0(available_mod_names$bundle.version[i-1],", ",available_mod_names$bundle.version[i])
}
}
head(available_mod_names)
head(table(available_mod_names$package))
suppressMessages(library(kableExtra))
suppressMessages(library(data.table))
suppressMessages(library(dplyr))
suppressMessages(library(tidyr))
suppressMessages(library(lubridate))
suppressMessages(library(ggplot2))
## load data
if(file.exists("all_data_combined.RDS")){
all_data_combined <- readRDS("all_data_combined.RDS")
}
all_final <- dir(pattern="all_final")
all_final
#### for ease, start with %utilization graph, all on same scale, can play with others later
utilization_data <- filter(all_data_combined,grepl("/",all_data_combined$value),metric=="%utilization cores/nodes") %>%
separate(value,into=c("cores","nodes"),sep="/") %>%
pivot_longer(cols=cores:nodes,names_to="unit",values_to="utilization") %>%
mutate_at(vars(utilization),as.integer)
all_data_combined <- new_data_combined
setwd("~/Projects/quick_start")
## load data
if(file.exists("all_data_combined.RDS")){
all_data_combined <- readRDS("all_data_combined.RDS")
}
#### for ease, start with %utilization graph, all on same scale, can play with others later
utilization_data <- filter(all_data_combined,grepl("/",all_data_combined$value),metric=="%utilization cores/nodes") %>%
separate(value,into=c("cores","nodes"),sep="/") %>%
pivot_longer(cols=cores:nodes,names_to="unit",values_to="utilization") %>%
mutate_at(vars(utilization),as.integer)
this_month <- month(Sys.Date())
this_year <- year(Sys.Date())
gg2_today <- ggplot(utilization_data %>% filter(format(utilization_data$date,"%d")==format(today(),"%d")),
aes(x=date,y=utilization,color=queue,linetype=unit)) +
geom_line() +
ylab("utilization today") +
xlab("") +
facet_grid(rows="machine", scales="free_y") +
scale_x_datetime(date_labels = "%k:%M", date_breaks='2 hour',date_minor_breaks='1 hour',
sec.axis=dup_axis(labels = scales::time_format("%I %p"))) +
theme_bw() +
theme(axis.text.x = element_text(angle=90,vjust=0.5))
gg2_month <- ggplot(utilization_data %>% filter(month(utilization_data$date)==this_month),
aes(x=date,y=utilization,color=queue,linetype=unit)) +
geom_line() +
ylab(paste0(month(this_month,abbr = FALSE, label=TRUE)," utilization")) +
xlab("") +
facet_grid(rows="machine", scales="free_y") +
scale_x_datetime(date_labels = "%a -- %d", date_breaks='1 day',date_minor_breaks='12 hour') +
theme_bw() +
theme(axis.text.x = element_text(angle=90, vjust=0.5))
gg2_year <- ggplot(utilization_data %>% filter(year(utilization_data$date)==this_year),
aes(x=date,y=utilization,color=queue,linetype=unit)) +
geom_line() +
ylab("utilization year to date") +
xlab("") +
facet_grid(rows="machine",scales="free_y") +
scale_x_datetime(date_labels = "%b-%d -- %U", date_breaks='1 week',date_minor_breaks='1 day') +
theme_bw() +
theme(axis.text.x = element_text(angle=90, vjust=0.5))
gg2_today
format(today(),"%d")
format(today(),"%m%d")
?format
format(today(),"%b%d")
format(today(),"%a%d")
format(today(),"%b%d")
format(today(),"%B %d")
gg2_today <- ggplot(utilization_data %>% filter(format(utilization_data$date,"%d")==format(today(),"%d")),
aes(x=date,y=utilization,color=queue,linetype=unit)) +
geom_line() +
ylab(paste0("Utilization today, ",format(today(),"%B %d"))) +
xlab("") +
facet_grid(rows="machine", scales="free_y") +
scale_x_datetime(date_labels = "%k:%M", date_breaks='2 hour',date_minor_breaks='1 hour',
sec.axis=dup_axis(labels = scales::time_format("%I %p"))) +
theme_bw() +
theme(axis.text.x = element_text(angle=90,vjust=0.5))
gg2_today
head(utilization_data)
head(format(utilization_data$date,"%d"))
head(utilization_data$date)
head(format(utilization_data$date,"%F"))
format(today(),"%F")
format(today(),"%Y %B")
this_month
