
################################
# data generated by
# squeue | grep "Limit\|Time" | \
#       grep -v "PartitionTimeLimit" | \
#       awk '{ print $1, $4, $8 }' >> ~/quick_start/ca_metered_jobs.txt
# sacct --cluster=cascades --start=$(date -d "-30min" +"%m/%d/%y-%H:%M") \
#       --end=$(date +"%m/%d/%y-%H:%M") --state=R -X -a \
#       -o JobID,Submit,Start,Eligible,Partition,Reservation,AllocNodes,AllocCPUS,ReqNodes,ReqCPUS,ReqGRES,Timelimit,Elapsed \
#       >> ~/quick_start/ca_finished_jobs.txt
################################

suppressMessages(library(kableExtra))
suppressMessages(library(data.table))
suppressMessages(library(dplyr))
suppressMessages(library(tidyr))
suppressMessages(library(lubridate))
suppressMessages(library(ggplot2))

################################
# read in data
################################

this_month <- month(Sys.Date())
this_year <- year(Sys.Date())

# first get jobs that were stuck in queue for QOS, BeginTime, or other partition limit
metered_files <- dir(pattern="metered_jobs.txt")
if(length(metered_files)>0){
    metered_jobs <- c()
    for(i in 1:length(metered_files)){
        metered_jobs <- rbind(metered_jobs,fread(metered_files[i],sep=" ",
                                                 data.table=FALSE,header=FALSE,col.names=c("jobid","reason","cluster")))
    }
}
if(length(dir("metered_jobs.RDS"))>0){
    metered_jobs <- rbind(readRDS("metered_jobs.RDS"),metered_jobs)
}

# now get jobs that finished
not_all_na <- function(x) any(!is.na(x))

if(file.exists("ca_finished_jobs.txt")){
    if(length(readLines("ca_finished_jobs.txt"))>2){
        ca_finished_jobs <- fread("sed 's/ /;;/g' ca_finished_jobs.txt | sed 's/[;][;]*/ /g'",
                                  skip=2,header=FALSE,data.table=FALSE,fill=TRUE,colClasses=c("character"))
        for(i in 1:nrow(ca_finished_jobs)){
            if(ca_finished_jobs[i,12]=="cascades"){
                ca_finished_jobs[i,11:13] <- ca_finished_jobs[i,10:12]
                ca_finished_jobs[i,10] <- "gpu:0"
            }
        }
        colnames(ca_finished_jobs) <- c("JobID","Submit","Start","Eligible","Partition","AllocNodes",
                                        "AllocCPUS","ReqNodes","ReqCPUS","ReqGRES","Timelimit","Elapsed","Cluster")
    }
}

if(file.exists("dt_finished_jobs.txt")){
    if(length(readLines("dt_finished_jobs.txt"))>2){
        dt_finished_jobs <- fread("sed 's/ /;;/g' dt_finished_jobs.txt | sed 's/[;][;]*/ /g'",
                                  skip=2,header=FALSE,data.table=FALSE,fill=TRUE,colClasses=c("character"))
        colnames(dt_finished_jobs) <- c("JobID","Submit","Start","Eligible","Partition","AllocNodes",
                                        "AllocCPUS","ReqNodes","ReqCPUS","Timelimit","Elapsed","Cluster")
        finished_jobs <- full_join(ca_finished_jobs,dt_finished_jobs)
    }
}

if(file.exists("hu_finished_jobs.txt")){
    if(length(readLines("hu_finished_jobs.txt"))>2){
        dt_finished_jobs <- fread("sed 's/ /;;/g' dt_finished_jobs.txt | sed 's/[;][;]*/ /g'",
                                  skip=2,header=FALSE,data.table=FALSE,fill=TRUE,colClasses=c("character"))
        colnames(dt_finished_jobs) <- c("JobID","Submit","Start","Eligible","Partition","AllocNodes",
                                        "AllocCPUS","ReqNodes","ReqCPUS","Timelimit","Elapsed","Cluster")
        
        hu_finished_jobs <- fread("sed 's/ /;;/g' hu_finished_jobs.txt | sed 's/[;][;]*/ /g'",
                                  skip=2,header=FALSE,data.table=FALSE,fill=TRUE,colClasses=c("character"))
        for(i in 1:nrow(hu_finished_jobs)){
            if(hu_finished_jobs[i,12]=="huckleberry"){
                hu_finished_jobs[i,11:13] <- hu_finished_jobs[i,10:12]
                hu_finished_jobs[i,10] <- "gpu:0"
            }
        }
        colnames(hu_finished_jobs) <- c("JobID","Submit","Start","Eligible","Partition","AllocNodes",
                                        "AllocCPUS","ReqNodes","ReqCPUS","ReqGRES","Timelimit","Elapsed","Cluster")
        finished_jobs <- full_join(finished_jobs,hu_finished_jobs)
    }
}



## default is not metered
finished_jobs$metered <- 0 
if(length(dir(paste0("finished_jobs_",this_month,"_",this_year,".RDS")))>0){
    finished_jobs <- rbind(readRDS(paste0("finished_jobs_",this_month,"_",this_year,".RDS")),finished_jobs)
}

# get queues we care about
general_queues <- fread("./queues_to_report.txt",header=FALSE)

################################
# filter and summarize data:
#   remove duplicates 
#   flag metered jobs (jobs not allowed to start right away)
#   calculate waittime
#   fix truncated v100_normal_q
#   filter to queues we care about
################################

finished_jobs <- finished_jobs[!duplicated(finished_jobs$JobID),]
temp <- paste(finished_jobs$JobID, finished_jobs$Cluster, sep="-")
finished_jobs <- finished_jobs %>% 
            mutate(metered = ifelse(temp %in% paste(metered_jobs$jobid, metered_jobs$cluster, sep="-"),1,metered),
                   waittime = as.numeric(parse_date_time(gsub("T","-",finished_jobs$Start),"Y:m:d-H:M:S") - parse_date_time(gsub("T","-",finished_jobs$Submit),"Y:m:d-H:M:S")))
finished_jobs$AllocCPUS <- as.numeric(finished_jobs$AllocCPUS)
finished_jobs$Partition <- ifelse(finished_jobs$Partition == "v100_norm+","v100_normal_q",finished_jobs$Partition)
finished_jobs <- finished_jobs[finished_jobs$Partition %in% general_queues$V1,]

# compresss metered data, remove job if it is finished
metered_jobs <- metered_jobs[!(paste(metered_jobs$jobid, metered_jobs$cluster, sep="-") %in% temp),]

################################
# plot
################################
cbbPalette <- c("#000000", "#D55E00", "#0072B2",
                "#FF00CC", "#F0E442", "#56B4E9",
                "#E69F00", "#CC79A7")
wait_time_plot_by_AllocCPU <- ggplot(finished_jobs[finished_jobs$metered==0,],aes(x=AllocCPUS,y=(waittime/60+1),color=finished_jobs$Partition)) +
        geom_point(position="jitter",size=1) +
        ylab("wait time in minutes+1") +
        xlab("AllocCPUS, log2 axis") +
        labs(color="Queue", title="Experimental work in progress -- please ignore") +
        facet_grid(rows="Cluster",scales="free_y") +
        theme_bw() +
        theme(axis.text.x = element_text(angle=90, vjust=0.5)) +
        scale_y_log10() +
        scale_x_continuous(trans="log2") +
    	scale_colour_manual(values=cbbPalette)

wait_time_plot_by_ReqNodes <- ggplot(finished_jobs[finished_jobs$metered==0,],
                                     aes(x=factor(ReqNodes),y=(waittime/60+1),color=factor(Partition))) +
    #geom_point(position="jitter",size=1) +
    geom_violin(scale="width") +
    ylab("wait time in minutes+1") +
    #xlab("AllocCPUS, log2 axis") +
    labs(color="Queue", title="Experimental work in progress -- please ignore") +
    facet_grid(rows="Cluster",scales="free_y") +
    theme_bw() +
    theme(axis.text.x = element_text(angle=90, vjust=0.5)) +
    scale_y_log10() 

wait_time_plot_by_ReqCPUS <- ggplot(finished_jobs[finished_jobs$metered==0,],
                                     aes(x=factor(ReqCPUS),y=(waittime/60+1),color=factor(Partition))) +
    #geom_point(position="jitter",size=1) +
    geom_violin(scale="width") +
    ylab("wait time in minutes+1") +
    #xlab("AllocCPUS, log2 axis") +
    labs(color="Queue", title="Experimental work in progress -- please ignore") +
    facet_grid(rows="Cluster",scales="free_y") +
    theme_bw() +
    theme(axis.text.x = element_text(angle=90, vjust=0.5)) +
    scale_y_log10() 


################################
# save data and delete old
################################
saveRDS(finished_jobs,file=paste0("finished_jobs_",this_month,"_",this_year,".RDS"))
saveRDS(metered_jobs,file="metered_jobs.RDS")
ggsave("wait_time_plot_by_AllocCPU.jpg",wait_time_plot_by_AllocCPU)

#### delete old data
## no reason to delete, we are overwriting on creation
#old_data <- c(metered_files,dir(pattern="finished_jobs.txt"))
#for(i in old_data){
#    file.remove(i)
#}


### end
